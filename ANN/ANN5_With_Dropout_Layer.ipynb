{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note : ANN with dropout layers does not surely increase accuracy thats why drop out layers can be very useful in case of extreme deep neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"../datasets/sonar_dataset.csv\" , header = None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the target column for number of records of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(60 , axis = 1)\n",
    "y = df[60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert target variable classes to 1 0 using one hot encoding and drop first column of dummy to avoid dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R\n",
       "0    111\n",
       "1     97\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y , drop_first = True)\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (52, 60))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ANN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an overfitting model which will perform well for training data but poorly for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.4808\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.7436\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.8269\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7885\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7949\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8013\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8526\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8205\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8269\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3685 - accuracy: 0.8397\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8205\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8654\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8654\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8462\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8526\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8718\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8718\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8782\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8846\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8846\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8782\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.8910\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8974\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.8782\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8910\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9038\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9231\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9038\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9167\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9231\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9487\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9038\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9359\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.1615 - accuracy: 0.9551\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1577 - accuracy: 0.9487\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9487\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9615\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9295\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9551\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9423\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1377 - accuracy: 0.9615\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9423\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9615\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9679\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9808\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9615\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9615\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9872\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9872\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9679\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9808\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9872\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9872\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 0.9808\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9808\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9936\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9936\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9808\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201e9a14520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  # Input layer 60 neurons\n",
    "  keras.layers.Dense(units = 60 , input_dim = X_train.shape[1] , activation = 'relu'),\n",
    "  \n",
    "  ## Hidden layer 1\n",
    "  keras.layers.Dense(units = 30 , activation = 'relu') ,\n",
    "  \n",
    "  ## Hidden layer 2\n",
    "  keras.layers.Dense(units = 15 , activation = 'relu') ,\n",
    "  \n",
    "  # Output layer use sigmoid activation function as binary classification\n",
    "  keras.layers.Dense(units = 1, activation = 'sigmoid') ,\n",
    "])\n",
    "\n",
    "# Adam optimizer is good\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train , epochs = 100 , batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6904798746109009, 0.75]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "# Round predicted values to 0 , 1\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78        27\n",
      "           1       0.80      0.64      0.71        25\n",
      "\n",
      "    accuracy                           0.75        52\n",
      "   macro avg       0.76      0.75      0.75        52\n",
      "weighted avg       0.76      0.75      0.75        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an ANN model with dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.7550 - accuracy: 0.4359\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.4487\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7193 - accuracy: 0.4551\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5256\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.4808\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5833\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.5192\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5641\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.5321\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5321\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5833\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5321\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5833\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5321\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.5897\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.5769\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6154\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5513\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.5769\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6538\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6154\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.5962\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6987\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6090\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6026\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.5833\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.5962\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6987\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6538\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.5769\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6474\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6987\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6603\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6859\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7372\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.6987\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7244\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7372\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7308\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.6795\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7244\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7628\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7692\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7308\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7372\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7628\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7949\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7308\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7885\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7436\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7692\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8077\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7821\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7628\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8013\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7949\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7821\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7692\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7949\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7885\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8526\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7436\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7821\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8269\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7949\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8462\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8141\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8526\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8782\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8141\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8718\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8269\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8397\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8526\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8782\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8526\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8462\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8205\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8397\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8462\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8654\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8590\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8397\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8269\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8462\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8397\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8654\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8590\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8462\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201eae436a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "  # Input layer 60 neurons\n",
    "  keras.layers.Dense(units = 60 , input_dim = X_train.shape[1] , activation = 'relu'),\n",
    "  \n",
    "  # Add dropout layer\n",
    "  keras.layers.Dropout(0.5) ,\n",
    "  \n",
    "  #Hidden layer 1\n",
    "  keras.layers.Dense(units = 30 , activation = 'relu') ,\n",
    "  \n",
    "  # Add dropout layer\n",
    "  keras.layers.Dropout(0.5) ,\n",
    "  \n",
    "  # Hidden layer 2\n",
    "  keras.layers.Dense(units = 15 , activation = 'relu') ,\n",
    "  \n",
    "  # Add dropout layer\n",
    "  keras.layers.Dropout(0.5),\n",
    "  \n",
    "  # Output layer use sigmoid activation function as binary classification\n",
    "  keras.layers.Dense(units = 1, activation = 'sigmoid') ,\n",
    "])\n",
    "\n",
    "# Adam optimizer is good\n",
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train , epochs = 100 , batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43743500113487244, 0.7307692170143127]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77        27\n",
      "           1       0.79      0.60      0.68        25\n",
      "\n",
      "    accuracy                           0.73        52\n",
      "   macro avg       0.74      0.73      0.72        52\n",
      "weighted avg       0.74      0.73      0.73        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "# Round predicted values to 0 , 1\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test , y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b095c78d4d0a65c3f456c494693e1a5b5771f8f860a0a9af68316c2e765deba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
